{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
      "Recognized Command: 5\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Recognized Command: 9\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Recognized Command: 1\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Recognized Command: 2\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Recognized Command: 2\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Recognized Command: 2\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Recognized Command: 4\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Recognized Command: 5\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Recognized Command: 0\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Recognized Command: 6\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Recognized Command: 3\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Recognized Command: 7\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Recognized Command: 9\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Recognized Command: 3\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Recognized Command: 1\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Recognized Command: 1\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Recognized Command: 5\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Recognized Command: 6\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Recognized Command: 2\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Recognized Command: 3\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Recognized Command: dog\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Recognized Command: dog\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Recognized Command: dog\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Recognized Command: dog\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Recognized Command: cat\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Recognized Command: bird\n",
      "Recording...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Recognized Command: dog\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio(duration=2, sample_rate=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print(\"Recording complete.\")\n",
    "    return audio_data.flatten(), sample_rate\n",
    "\n",
    "# Normalize audio to range [-1, 1]\n",
    "def normalize_audio(audio):\n",
    "    return audio.astype(np.float32) / 32768.0\n",
    "\n",
    "# Extract MFCC features\n",
    "def extract_mfcc(audio, sr, duration=2, n_mfcc=40, frames=32):\n",
    "    audio = normalize_audio(audio)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    if mfcc.shape[1] < frames:\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, frames - mfcc.shape[1])), mode='constant')\n",
    "    elif mfcc.shape[1] > frames:\n",
    "        mfcc = mfcc[:, :frames]\n",
    "    mfcc = np.expand_dims(mfcc, axis=-1)  # Add channel dimension\n",
    "    mfcc = np.expand_dims(mfcc, axis=0)  # Add batch dimension\n",
    "    return mfcc\n",
    "\n",
    "# Recognize command from microphone\n",
    "def recognize_command(model, commands, duration=2):\n",
    "    audio, sr = record_audio(duration)\n",
    "    mfcc = extract_mfcc(audio, sr)\n",
    "    prediction = model.predict(mfcc)\n",
    "    predicted_command = commands[np.argmax(prediction)]\n",
    "    print(f\"Recognized Command: {predicted_command}\")\n",
    "    return predicted_command\n",
    "\n",
    "# Main GUI Application\n",
    "class VoiceCommandApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Learn App\")\n",
    "        self.root.geometry(\"600x600\")\n",
    "        \n",
    "        # Load models\n",
    "        self.number_model = load_model(\"numbersv3.h5\")  # Trained model for recognizing numbers\n",
    "        self.motion_model = load_model(\"motions.h5\")  # Trained model for motions (up, down, left, right)\n",
    "        self.animal_model = load_model(\"animalsv3.h5\")  # Trained model for recognizing animals\n",
    "        self.number_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Compile model\n",
    "        self.motion_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        self.animal_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        self.commands = ['up', 'down', 'left', 'right']\n",
    "        self.number_commands = [str(i) for i in range(10)]  # Numbers 0-9\n",
    "        self.animal_commands = ['cat', 'dog', 'bird']\n",
    "        \n",
    "        # Set background color\n",
    "        self.bg_image_path = \"back.png\"  # Replace with your background image file path\n",
    "        if not os.path.exists(self.bg_image_path):\n",
    "            raise FileNotFoundError(f\"Background image file not found: {self.bg_image_path}\")\n",
    "        \n",
    "        bg_image = Image.open(self.bg_image_path)\n",
    "        bg_image = bg_image.resize((600, 600))  # Resize to fit the window size\n",
    "        self.bg_photo = ImageTk.PhotoImage(bg_image, master=root)\n",
    "        \n",
    "        # Start menu with 3 options\n",
    "        self.create_start_menu()\n",
    "\n",
    "    def create_start_menu(self):\n",
    "        # Clear the window to ensure it's empty before showing the menu\n",
    "        self.clear_window()\n",
    "        \n",
    "        # Set background image\n",
    "        self.set_background()\n",
    "\n",
    "        # Header\n",
    "        header_label = tk.Label(self.root, text=\"Welcome Back!\", font=(\"Helvetica\", 30, \"bold\"), fg=\"green\", bg=\"#FFFFFF\")\n",
    "        header_label.place(relx=0.5, rely=0.2, anchor='center')  # Center header\n",
    "        \n",
    "        # Buttons for options\n",
    "        learn_numbers_btn = tk.Button(self.root, text=\"Learn Numbers\", font=(\"Helvetica\", 16), bg=\"#81C784\", command=self.learn_numbers)\n",
    "        learn_numbers_btn.place(relx=0.5, rely=0.4, anchor='center')  # Center button\n",
    "\n",
    "        learn_motions_btn = tk.Button(self.root, text=\"Learn Motions\", font=(\"Helvetica\", 16), bg=\"#81C784\", command=self.learn_motions)\n",
    "        learn_motions_btn.place(relx=0.5, rely=0.5, anchor='center')  # Center button\n",
    "\n",
    "        learn_animals_btn = tk.Button(self.root, text=\"Learn Animals\", font=(\"Helvetica\", 16), bg=\"#81C784\", command=self.learn_animals)\n",
    "        learn_animals_btn.place(relx=0.5, rely=0.6, anchor='center')  # Center button\n",
    "\n",
    "    def back_to_start_menu(self):\n",
    "        # Function to go back to the start menu\n",
    "        self.create_start_menu()\n",
    "\n",
    "    def learn_numbers(self):\n",
    "        # Function for learning numbers\n",
    "        self.clear_window()  # Clear the window\n",
    "        self.set_background()\n",
    "\n",
    "        # Randomly select a number (0-9)\n",
    "        number = np.random.choice(self.number_commands)\n",
    "        \n",
    "        # Display the number image\n",
    "        number_image_path = f\"images/numbers/{number}.png\"  # Replace with path to your number images (0.png, 1.png, etc.)\n",
    "        number_image = Image.open(number_image_path)\n",
    "        number_image = number_image.resize((150, 150))\n",
    "        number_photo = ImageTk.PhotoImage(number_image, master=self.root)\n",
    "        \n",
    "        number_label = tk.Label(self.root, image=number_photo)\n",
    "        number_label.image = number_photo  # Keep reference to prevent garbage collection\n",
    "        number_label.place(relx=0.5, rely=0.3, anchor='center')\n",
    "\n",
    "        # Prompt to say the number\n",
    "        prompt_label = tk.Label(self.root, text=\"Say the number\", font=(\"Helvetica\", 18), fg=\"#81C784\", bg=\"#FFFFFF\")\n",
    "        prompt_label.place(relx=0.5, rely=0.5, anchor='center')\n",
    "\n",
    "        # Feedback label to show whether it's correct or not\n",
    "        self.feedback_label = tk.Label(self.root, text=\"\", font=(\"Helvetica\", 16), fg=\"#FF6347\", bg=\"#FFFFFF\")\n",
    "        self.feedback_label.place(relx=0.5, rely=0.6, anchor='center')\n",
    "\n",
    "        # Record button\n",
    "        record_button = tk.Button(self.root, text=\"Record\", font=(\"Helvetica\", 16), bg=\"#81C784\", command=lambda: self.check_number(number, number_label, prompt_label))\n",
    "        record_button.place(relx=0.5, rely=0.7, anchor='center')\n",
    "        \n",
    "        # Back button\n",
    "        back_button = tk.Button(self.root, text=\"Back\", font=(\"Helvetica\", 16), bg=\"#FFB6C1\", command=self.back_to_start_menu)\n",
    "        back_button.place(relx=0.5, rely=0.8, anchor='center')\n",
    "\n",
    "    def check_number(self, number, number_label, prompt_label):\n",
    "        # Recognize number command\n",
    "        try:\n",
    "            command = recognize_command(self.number_model, self.number_commands)\n",
    "            if command == number:\n",
    "                self.feedback_label.config(text=\"Correct!\", fg=\"green\")\n",
    "                self.root.after(2000, self.learn_numbers)  # Wait 2 seconds before changing the number\n",
    "            else:\n",
    "                self.feedback_label.config(text=\"Wrong, try again!\", fg=\"red\")\n",
    "        except Exception as e:\n",
    "            self.feedback_label.config(text=f\"Error: {e}\", fg=\"red\")\n",
    "\n",
    "    def learn_motions(self):\n",
    "        # Function for learning motions\n",
    "        self.clear_window()\n",
    "        self.set_background()\n",
    "\n",
    "        # Create a smaller canvas to act as the box for Dora (200x200)\n",
    "        self.canvas = tk.Canvas(self.root, width=200, height=200, bg=\"#FFFFFF\")\n",
    "        self.canvas.place(relx=0.5, rely=0.4, anchor='center')  # Center canvas\n",
    "\n",
    "        # Create Dora inside the canvas (initial position)\n",
    "        self.dora_image_path = \"dora.png\"  # Replace with your Dora image path\n",
    "        self.dora_image = Image.open(self.dora_image_path)\n",
    "        self.dora_image = self.dora_image.resize((80, 80))  # Resize Dora to fit in the smaller box\n",
    "        self.dora_photo = ImageTk.PhotoImage(self.dora_image)\n",
    "\n",
    "        # Place Dora inside the box (initial position)\n",
    "        self.dora_label = self.canvas.create_image(100, 100, image=self.dora_photo)  # Initial position (center of box)\n",
    "        \n",
    "        # Display instructions for learning motions\n",
    "        tk.Label(self.root, text=\"Say one of : Up, Down, Left, Right\", font=(\"Helvetica\", 16), fg=\"#81C784\",bg=\"#FFFFFF\").place(relx=0.5, rely=0.6, anchor='center')\n",
    "        \n",
    "        # Record button for motion commands\n",
    "        record_button = tk.Button(self.root, text=\"Record\", font=(\"Helvetica\", 16), bg=\"#81C784\", command=self.perform_motion)\n",
    "        record_button.place(relx=0.5, rely=0.7, anchor='center')\n",
    "\n",
    "        # Back button\n",
    "        back_button = tk.Button(self.root, text=\"Back\", font=(\"Helvetica\", 16), bg=\"#FFB6C1\", command=self.back_to_start_menu)\n",
    "        back_button.place(relx=0.5, rely=0.8, anchor='center')\n",
    "\n",
    "    def perform_motion(self):\n",
    "        # Recognize motion command\n",
    "        try:\n",
    "            command = recognize_command(self.motion_model, self.commands)\n",
    "            if command == 'up':\n",
    "                self.move_dora(\"up\")\n",
    "                #self.feedback_label.config(text=\"Correct, Dora is moving Up!\", fg=\"green\")\n",
    "            elif command == 'down':\n",
    "                self.move_dora(\"down\")\n",
    "               # self.feedback_label.config(text=\"Correct, Dora is moving Down!\", fg=\"green\")\n",
    "            elif command == 'left':\n",
    "                self.move_dora(\"left\")\n",
    "                #self.feedback_label.config(text=\"Correct, Dora is moving Left!\", fg=\"green\")\n",
    "            elif command == 'right':\n",
    "                self.move_dora(\"right\")\n",
    "               # self.feedback_label.config(text=\"Correct, Dora is moving Right!\", fg=\"green\")\n",
    "            else:\n",
    "                self.feedback_label.config(text=\"Wrong, try again!\", fg=\"red\")\n",
    "        except Exception as e:\n",
    "            self.feedback_label.config(text=f\"Error: {e}\", fg=\"red\")\n",
    "\n",
    "    def move_dora(self, direction):\n",
    "        # Get current coordinates of Dora\n",
    "        current_x, current_y = self.canvas.coords(self.dora_label)\n",
    "\n",
    "        # Define the smaller box boundaries (200x200)\n",
    "        box_left = 0\n",
    "        box_top = 0\n",
    "        box_right = 200\n",
    "        box_bottom = 200\n",
    "\n",
    "        # Move Dora according to the command, within the box boundaries\n",
    "        if direction == \"up\" and current_y > 50:\n",
    "            self.canvas.move(self.dora_label, 0, -50)  # Move Dora up\n",
    "        elif direction == \"down\" and current_y < 150:\n",
    "            self.canvas.move(self.dora_label, 0, 50)  # Move Dora down\n",
    "        elif direction == \"left\" and current_x > 50:\n",
    "            self.canvas.move(self.dora_label, -50, 0)  # Move Dora left\n",
    "        elif direction == \"right\" and current_x < 150:\n",
    "            self.canvas.move(self.dora_label, 50, 0)  # Move Dora right\n",
    "\n",
    "    def learn_animals(self):\n",
    "        # Function for learning animals\n",
    "        self.clear_window()  # Clear the window\n",
    "        self.set_background()\n",
    "\n",
    "        # Randomly select an animal\n",
    "        animal = np.random.choice(self.animal_commands)\n",
    "        \n",
    "        # Display the animal image\n",
    "        animal_image_path = f\"images/animals/{animal}.png\"  # Replace with path to your animal images (cat.png, dog.png, etc.)\n",
    "        animal_image = Image.open(animal_image_path)\n",
    "        animal_image = animal_image.resize((150, 150))\n",
    "        animal_photo = ImageTk.PhotoImage(animal_image, master=self.root)\n",
    "        \n",
    "        animal_label = tk.Label(self.root, image=animal_photo)\n",
    "        animal_label.image = animal_photo  # Keep reference to prevent garbage collection\n",
    "        animal_label.place(relx=0.5, rely=0.3, anchor='center')\n",
    "\n",
    "        # Prompt to say the animal\n",
    "        prompt_label = tk.Label(self.root, text=\"Say the animal\", font=(\"Helvetica\", 18), fg=\"#81C784\", bg=\"#FFFFFF\")\n",
    "        prompt_label.place(relx=0.5, rely=0.5, anchor='center')\n",
    "\n",
    "        # Feedback label to show whether it's correct or not\n",
    "        self.feedback_label = tk.Label(self.root, text=\"\", font=(\"Helvetica\", 16), fg=\"#FF6347\", bg=\"#FFFFFF\")\n",
    "        self.feedback_label.place(relx=0.5, rely=0.6, anchor='center')\n",
    "\n",
    "        # Record button\n",
    "        record_button = tk.Button(self.root, text=\"Record\", font=(\"Helvetica\", 16), bg=\"#81C784\", command=lambda: self.check_animal(animal, animal_label))\n",
    "        record_button.place(relx=0.5, rely=0.7, anchor='center')\n",
    "\n",
    "        # Back button\n",
    "        back_button = tk.Button(self.root, text=\"Back\", font=(\"Helvetica\", 16), bg=\"#FFB6C1\", command=self.back_to_start_menu)\n",
    "        back_button.place(relx=0.5, rely=0.8, anchor='center')\n",
    "\n",
    "    def check_animal(self, animal, animal_label):\n",
    "        # Recognize animal command\n",
    "        try:\n",
    "            command = recognize_command(self.animal_model, self.animal_commands)\n",
    "            if command == animal:\n",
    "                self.feedback_label.config(text=\"Correct!\", fg=\"green\")\n",
    "                self.root.after(2000, self.learn_animals) \n",
    "            else:\n",
    "                self.feedback_label.config(text=\"Wrong, try again!\", fg=\"red\")\n",
    "        except Exception as e:\n",
    "            self.feedback_label.config(text=f\"Error: {e}\", fg=\"red\")\n",
    "\n",
    "    def set_background(self):\n",
    "        bg_label = tk.Label(self.root, image=self.bg_photo)\n",
    "        bg_label.place(relwidth=1, relheight=1)\n",
    "\n",
    "    def clear_window(self):\n",
    "        for widget in self.root.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "app = VoiceCommandApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
